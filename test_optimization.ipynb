{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lunli/anaconda3/envs/ML Algo/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package stopwords to /Users/lunli/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Optional, Any, Callable\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "# torch\n",
    "import torch\n",
    "from torch import nn\n",
    "# transformer\n",
    "from transformers.optimization import AdamW, get_scheduler, SchedulerType\n",
    "# local\n",
    "from NlpAnalytics import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "### load BERT Classifier\n",
    "loader = BertClassifierLoader(ClassifierType.BERT_CLASSIFIER_HF, \"bert-base-uncased\", 2, 0.1, load_tokenizer=True)\n",
    "# native\n",
    "# loader = BertClassifierLoader(ClassifierType.BERT_CLASSIFIER, \"bert-base-uncased\", 2, 0.1, hidden_dims=[768], load_tokenizer=True)\n",
    "model, tokenizer = loader.model, loader.tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdamNLP + Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lunli/anaconda3/envs/ML Algo/lib/python3.10/site-packages/transformers/optimization.py:457: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamNLP(model)\n",
    "scheduler = optimizer.compile_schedule(total_num_steps=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo of AdamW + Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### prepare everything\n",
    "root_path = \"./NlpAnalytics/data/dummy_data/\"\n",
    "# load dataset, split into input (X) and output (y) variables\n",
    "dataframe = pd.read_csv(os.path.join(root_path, \"ionosphere.csv\"), header=None)\n",
    "dataset = dataframe.values\n",
    "X = dataset[:,0:34].astype(float)\n",
    "y = dataset[:,34]\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "y = encoder.transform(y)\n",
    "# convert into PyTorch tensors\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32).reshape(-1, 1)\n",
    " # train-test split for evaluation of the model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True)\n",
    "# create model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(34, 34),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(34, 1),\n",
    "    nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lunli/anaconda3/envs/ML Algo/lib/python3.10/site-packages/transformers/optimization.py:457: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "### training set up\n",
    "n_epochs = 50\n",
    "batch_size = 24\n",
    "batch_start = torch.arange(0, len(X_train), batch_size)\n",
    "loss_fn = nn.BCELoss()\n",
    "param_optimizer = list(model.named_parameters())\n",
    "# no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [{'params': [p for _, p in param_optimizer], 'weight_decay': 0.05}]\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=1e-3)\n",
    "scheduler = get_scheduler(SchedulerType.LINEAR, optimizer=optimizer, num_warmup_steps=0, num_training_steps=550)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0009981818181818182\n",
      "0.0009963636363636364\n",
      "0.0009945454545454546\n",
      "0.0009927272727272727\n",
      "0.000990909090909091\n",
      "0.000989090909090909\n",
      "0.0009872727272727273\n",
      "0.0009854545454545454\n",
      "0.0009836363636363636\n",
      "0.0009818181818181818\n",
      "0.00098\n",
      "0.0009781818181818181\n",
      "0.0009763636363636363\n",
      "0.0009745454545454545\n",
      "0.0009727272727272728\n",
      "0.000970909090909091\n",
      "0.0009690909090909091\n",
      "0.0009672727272727273\n",
      "0.0009654545454545455\n",
      "0.0009636363636363637\n",
      "0.0009618181818181818\n",
      "0.00096\n",
      "0.0009581818181818182\n",
      "0.0009563636363636365\n",
      "0.0009545454545454546\n",
      "0.0009527272727272727\n",
      "0.0009509090909090909\n",
      "0.0009490909090909091\n",
      "0.0009472727272727273\n",
      "0.0009454545454545454\n",
      "0.0009436363636363636\n",
      "0.0009418181818181818\n",
      "0.00094\n",
      "0.0009381818181818183\n",
      "0.0009363636363636364\n",
      "0.0009345454545454546\n",
      "0.0009327272727272728\n",
      "0.000930909090909091\n",
      "0.0009290909090909091\n",
      "0.0009272727272727273\n",
      "0.0009254545454545454\n",
      "0.0009236363636363636\n",
      "0.0009218181818181819\n",
      "0.00092\n",
      "0.0009181818181818182\n",
      "0.0009163636363636364\n",
      "0.0009145454545454546\n",
      "0.0009127272727272727\n",
      "0.0009109090909090909\n",
      "0.0009090909090909091\n",
      "0.0009072727272727273\n",
      "0.0009054545454545454\n",
      "0.0009036363636363637\n",
      "0.0009018181818181819\n",
      "0.0009000000000000001\n",
      "0.0008981818181818183\n",
      "0.0008963636363636363\n",
      "0.0008945454545454545\n",
      "0.0008927272727272727\n",
      "0.0008909090909090909\n",
      "0.000889090909090909\n",
      "0.0008872727272727273\n",
      "0.0008854545454545455\n",
      "0.0008836363636363637\n",
      "0.0008818181818181819\n",
      "0.00088\n",
      "0.0008781818181818182\n",
      "0.0008763636363636364\n",
      "0.0008745454545454546\n",
      "0.0008727272727272727\n",
      "0.0008709090909090909\n",
      "0.0008690909090909092\n",
      "0.0008672727272727273\n",
      "0.0008654545454545454\n",
      "0.0008636363636363636\n",
      "0.0008618181818181818\n",
      "0.00086\n",
      "0.0008581818181818182\n",
      "0.0008563636363636363\n",
      "0.0008545454545454545\n",
      "0.0008527272727272728\n",
      "0.000850909090909091\n",
      "0.0008490909090909091\n",
      "0.0008472727272727273\n",
      "0.0008454545454545455\n",
      "0.0008436363636363637\n",
      "0.0008418181818181819\n",
      "0.00084\n",
      "0.0008381818181818181\n",
      "0.0008363636363636363\n",
      "0.0008345454545454546\n",
      "0.0008327272727272727\n",
      "0.0008309090909090909\n",
      "0.0008290909090909091\n",
      "0.0008272727272727273\n",
      "0.0008254545454545455\n",
      "0.0008236363636363636\n",
      "0.0008218181818181818\n",
      "0.00082\n",
      "0.0008181818181818183\n",
      "0.0008163636363636364\n",
      "0.0008145454545454546\n",
      "0.0008127272727272728\n",
      "0.000810909090909091\n",
      "0.0008090909090909092\n",
      "0.0008072727272727272\n",
      "0.0008054545454545454\n",
      "0.0008036363636363636\n",
      "0.0008018181818181818\n",
      "0.0008\n",
      "0.0007981818181818182\n",
      "0.0007963636363636364\n",
      "0.0007945454545454546\n",
      "0.0007927272727272727\n",
      "0.0007909090909090909\n",
      "0.0007890909090909091\n",
      "0.0007872727272727273\n",
      "0.0007854545454545455\n",
      "0.0007836363636363637\n",
      "0.0007818181818181819\n",
      "0.0007800000000000001\n",
      "0.0007781818181818182\n",
      "0.0007763636363636363\n",
      "0.0007745454545454545\n",
      "0.0007727272727272727\n",
      "0.0007709090909090909\n",
      "0.000769090909090909\n",
      "0.0007672727272727272\n",
      "0.0007654545454545455\n",
      "0.0007636363636363637\n",
      "0.0007618181818181819\n",
      "0.00076\n",
      "0.0007581818181818182\n",
      "0.0007563636363636364\n",
      "0.0007545454545454546\n",
      "0.0007527272727272728\n",
      "0.0007509090909090909\n",
      "0.0007490909090909091\n",
      "0.0007472727272727273\n",
      "0.0007454545454545455\n",
      "0.0007436363636363636\n",
      "0.0007418181818181818\n",
      "0.00074\n",
      "0.0007381818181818182\n",
      "0.0007363636363636363\n",
      "0.0007345454545454545\n",
      "0.0007327272727272728\n",
      "0.000730909090909091\n",
      "0.0007290909090909092\n",
      "0.0007272727272727273\n",
      "0.0007254545454545455\n",
      "0.0007236363636363637\n",
      "0.0007218181818181819\n",
      "0.0007199999999999999\n",
      "0.0007181818181818181\n",
      "0.0007163636363636363\n",
      "0.0007145454545454546\n",
      "0.0007127272727272728\n",
      "0.0007109090909090909\n",
      "0.0007090909090909091\n",
      "0.0007072727272727273\n",
      "0.0007054545454545455\n",
      "0.0007036363636363636\n",
      "0.0007018181818181818\n",
      "0.0007\n",
      "0.0006981818181818183\n",
      "0.0006963636363636365\n",
      "0.0006945454545454546\n",
      "0.0006927272727272728\n",
      "0.0006909090909090909\n",
      "0.0006890909090909091\n",
      "0.0006872727272727272\n",
      "0.0006854545454545454\n",
      "0.0006836363636363636\n",
      "0.0006818181818181818\n",
      "0.00068\n",
      "0.0006781818181818182\n",
      "0.0006763636363636364\n",
      "0.0006745454545454546\n",
      "0.0006727272727272728\n",
      "0.0006709090909090909\n",
      "0.0006690909090909091\n",
      "0.0006672727272727273\n",
      "0.0006654545454545455\n",
      "0.0006636363636363638\n",
      "0.0006618181818181819\n",
      "0.00066\n",
      "0.0006581818181818182\n",
      "0.0006563636363636364\n",
      "0.0006545454545454545\n",
      "0.0006527272727272727\n",
      "0.0006509090909090909\n",
      "0.0006490909090909091\n",
      "0.0006472727272727272\n",
      "0.0006454545454545455\n",
      "0.0006436363636363637\n",
      "0.0006418181818181819\n",
      "0.00064\n",
      "0.0006381818181818182\n",
      "0.0006363636363636364\n",
      "0.0006345454545454546\n",
      "0.0006327272727272728\n",
      "0.0006309090909090908\n",
      "0.0006290909090909091\n",
      "0.0006272727272727273\n",
      "0.0006254545454545455\n",
      "0.0006236363636363636\n",
      "0.0006218181818181818\n",
      "0.00062\n",
      "0.0006181818181818182\n",
      "0.0006163636363636364\n",
      "0.0006145454545454545\n",
      "0.0006127272727272727\n",
      "0.000610909090909091\n",
      "0.0006090909090909092\n",
      "0.0006072727272727273\n",
      "0.0006054545454545455\n",
      "0.0006036363636363637\n",
      "0.0006018181818181818\n",
      "0.0006\n",
      "0.0005981818181818181\n",
      "0.0005963636363636363\n",
      "0.0005945454545454546\n",
      "0.0005927272727272728\n",
      "0.0005909090909090909\n",
      "0.0005890909090909091\n",
      "0.0005872727272727273\n",
      "0.0005854545454545455\n",
      "0.0005836363636363636\n",
      "0.0005818181818181818\n",
      "0.00058\n",
      "0.0005781818181818182\n",
      "0.0005763636363636365\n",
      "0.0005745454545454546\n",
      "0.0005727272727272727\n",
      "0.0005709090909090909\n",
      "0.0005690909090909091\n",
      "0.0005672727272727272\n",
      "0.0005654545454545454\n",
      "0.0005636363636363636\n",
      "0.0005618181818181818\n",
      "0.0005600000000000001\n",
      "0.0005581818181818182\n",
      "0.0005563636363636364\n",
      "0.0005545454545454546\n",
      "0.0005527272727272728\n",
      "0.0005509090909090909\n",
      "0.0005490909090909091\n",
      "0.0005472727272727273\n",
      "0.0005454545454545455\n",
      "0.0005436363636363635\n",
      "0.0005418181818181818\n",
      "0.00054\n",
      "0.0005381818181818182\n",
      "0.0005363636363636364\n",
      "0.0005345454545454545\n",
      "0.0005327272727272727\n",
      "0.0005309090909090909\n",
      "0.0005290909090909091\n",
      "0.0005272727272727272\n",
      "0.0005254545454545455\n",
      "0.0005236363636363637\n",
      "0.0005218181818181819\n",
      "0.0005200000000000001\n",
      "0.0005181818181818182\n",
      "0.0005163636363636364\n",
      "0.0005145454545454545\n",
      "0.0005127272727272727\n",
      "0.0005109090909090908\n",
      "0.000509090909090909\n",
      "0.0005072727272727273\n",
      "0.0005054545454545455\n",
      "0.0005036363636363637\n",
      "0.0005018181818181818\n",
      "0.0005\n",
      "0.0004981818181818182\n",
      "0.0004963636363636364\n",
      "0.0004945454545454545\n",
      "0.0004927272727272727\n",
      "0.0004909090909090909\n",
      "0.0004890909090909091\n",
      "0.00048727272727272725\n",
      "0.0004854545454545455\n",
      "0.00048363636363636366\n",
      "0.00048181818181818184\n",
      "0.00048\n",
      "0.00047818181818181824\n",
      "0.00047636363636363637\n",
      "0.00047454545454545454\n",
      "0.0004727272727272727\n",
      "0.0004709090909090909\n",
      "0.00046909090909090913\n",
      "0.0004672727272727273\n",
      "0.0004654545454545455\n",
      "0.00046363636363636366\n",
      "0.0004618181818181818\n",
      "0.00046\n",
      "0.0004581818181818182\n",
      "0.00045636363636363637\n",
      "0.00045454545454545455\n",
      "0.0004527272727272727\n",
      "0.00045090909090909095\n",
      "0.00044909090909090913\n",
      "0.00044727272727272725\n",
      "0.00044545454545454543\n",
      "0.00044363636363636366\n",
      "0.00044181818181818184\n",
      "0.00044\n",
      "0.0004381818181818182\n",
      "0.00043636363636363637\n",
      "0.0004345454545454546\n",
      "0.0004327272727272727\n",
      "0.0004309090909090909\n",
      "0.0004290909090909091\n",
      "0.00042727272727272726\n",
      "0.0004254545454545455\n",
      "0.00042363636363636366\n",
      "0.00042181818181818184\n",
      "0.00042\n",
      "0.00041818181818181814\n",
      "0.00041636363636363637\n",
      "0.00041454545454545455\n",
      "0.0004127272727272727\n",
      "0.0004109090909090909\n",
      "0.00040909090909090913\n",
      "0.0004072727272727273\n",
      "0.0004054545454545455\n",
      "0.0004036363636363636\n",
      "0.0004018181818181818\n",
      "0.0004\n",
      "0.0003981818181818182\n",
      "0.0003963636363636364\n",
      "0.00039454545454545455\n",
      "0.00039272727272727273\n",
      "0.00039090909090909096\n",
      "0.0003890909090909091\n",
      "0.00038727272727272726\n",
      "0.00038545454545454544\n",
      "0.0003836363636363636\n",
      "0.00038181818181818184\n",
      "0.00038\n",
      "0.0003781818181818182\n",
      "0.0003763636363636364\n",
      "0.00037454545454545455\n",
      "0.00037272727272727273\n",
      "0.0003709090909090909\n",
      "0.0003690909090909091\n",
      "0.00036727272727272726\n",
      "0.0003654545454545455\n",
      "0.00036363636363636367\n",
      "0.00036181818181818185\n",
      "0.00035999999999999997\n",
      "0.00035818181818181815\n",
      "0.0003563636363636364\n",
      "0.00035454545454545455\n",
      "0.00035272727272727273\n",
      "0.0003509090909090909\n",
      "0.00034909090909090914\n",
      "0.0003472727272727273\n",
      "0.00034545454545454544\n",
      "0.0003436363636363636\n",
      "0.0003418181818181818\n",
      "0.00034\n",
      "0.0003381818181818182\n",
      "0.0003363636363636364\n",
      "0.00033454545454545456\n",
      "0.00033272727272727273\n",
      "0.00033090909090909096\n",
      "0.0003290909090909091\n",
      "0.00032727272727272726\n",
      "0.00032545454545454544\n",
      "0.0003236363636363636\n",
      "0.00032181818181818185\n",
      "0.00032\n",
      "0.0003181818181818182\n",
      "0.0003163636363636364\n",
      "0.00031454545454545456\n",
      "0.00031272727272727273\n",
      "0.0003109090909090909\n",
      "0.0003090909090909091\n",
      "0.00030727272727272727\n",
      "0.0003054545454545455\n",
      "0.0003036363636363637\n",
      "0.00030181818181818185\n",
      "0.0003\n",
      "0.00029818181818181815\n",
      "0.0002963636363636364\n",
      "0.00029454545454545456\n",
      "0.00029272727272727274\n",
      "0.0002909090909090909\n",
      "0.0002890909090909091\n",
      "0.0002872727272727273\n",
      "0.00028545454545454544\n",
      "0.0002836363636363636\n",
      "0.0002818181818181818\n",
      "0.00028000000000000003\n",
      "0.0002781818181818182\n",
      "0.0002763636363636364\n",
      "0.00027454545454545456\n",
      "0.00027272727272727274\n",
      "0.0002709090909090909\n",
      "0.0002690909090909091\n",
      "0.00026727272727272727\n",
      "0.00026545454545454545\n",
      "0.0002636363636363636\n",
      "0.00026181818181818185\n",
      "0.00026000000000000003\n",
      "0.0002581818181818182\n",
      "0.00025636363636363633\n",
      "0.0002545454545454545\n",
      "0.00025272727272727274\n",
      "0.0002509090909090909\n",
      "0.0002490909090909091\n",
      "0.00024727272727272727\n",
      "0.00024545454545454545\n",
      "0.00024363636363636362\n",
      "0.00024181818181818183\n",
      "0.00024\n",
      "0.00023818181818181818\n",
      "0.00023636363636363636\n",
      "0.00023454545454545456\n",
      "0.00023272727272727274\n",
      "0.0002309090909090909\n",
      "0.0002290909090909091\n",
      "0.00022727272727272727\n",
      "0.00022545454545454548\n",
      "0.00022363636363636363\n",
      "0.00022181818181818183\n",
      "0.00022\n",
      "0.00021818181818181818\n",
      "0.00021636363636363636\n",
      "0.00021454545454545454\n",
      "0.00021272727272727274\n",
      "0.00021090909090909092\n",
      "0.00020909090909090907\n",
      "0.00020727272727272727\n",
      "0.00020545454545454545\n",
      "0.00020363636363636366\n",
      "0.0002018181818181818\n",
      "0.0002\n",
      "0.0001981818181818182\n",
      "0.00019636363636363636\n",
      "0.00019454545454545454\n",
      "0.00019272727272727272\n",
      "0.00019090909090909092\n",
      "0.0001890909090909091\n",
      "0.00018727272727272728\n",
      "0.00018545454545454545\n",
      "0.00018363636363636363\n",
      "0.00018181818181818183\n",
      "0.00017999999999999998\n",
      "0.0001781818181818182\n",
      "0.00017636363636363637\n",
      "0.00017454545454545457\n",
      "0.00017272727272727272\n",
      "0.0001709090909090909\n",
      "0.0001690909090909091\n",
      "0.00016727272727272728\n",
      "0.00016545454545454548\n",
      "0.00016363636363636363\n",
      "0.0001618181818181818\n",
      "0.00016\n",
      "0.0001581818181818182\n",
      "0.00015636363636363637\n",
      "0.00015454545454545454\n",
      "0.00015272727272727275\n",
      "0.00015090909090909093\n",
      "0.00014909090909090908\n",
      "0.00014727272727272728\n",
      "0.00014545454545454546\n",
      "0.00014363636363636366\n",
      "0.0001418181818181818\n",
      "0.00014000000000000001\n",
      "0.0001381818181818182\n",
      "0.00013636363636363637\n",
      "0.00013454545454545455\n",
      "0.00013272727272727272\n",
      "0.00013090909090909093\n",
      "0.0001290909090909091\n",
      "0.00012727272727272725\n",
      "0.00012545454545454546\n",
      "0.00012363636363636364\n",
      "0.00012181818181818181\n",
      "0.00012\n",
      "0.00011818181818181818\n",
      "0.00011636363636363637\n",
      "0.00011454545454545455\n",
      "0.00011272727272727274\n",
      "0.00011090909090909092\n",
      "0.00010909090909090909\n",
      "0.00010727272727272727\n",
      "0.00010545454545454546\n",
      "0.00010363636363636364\n",
      "0.00010181818181818183\n",
      "0.0001\n",
      "9.818181818181818e-05\n",
      "9.636363636363636e-05\n",
      "9.454545454545455e-05\n",
      "9.272727272727273e-05\n",
      "9.090909090909092e-05\n",
      "8.90909090909091e-05\n",
      "8.727272727272728e-05\n",
      "8.545454545454545e-05\n",
      "8.363636363636364e-05\n",
      "8.181818181818182e-05\n",
      "8e-05\n",
      "7.818181818181818e-05\n",
      "7.636363636363637e-05\n",
      "7.454545454545454e-05\n",
      "7.272727272727273e-05\n",
      "7.09090909090909e-05\n",
      "6.90909090909091e-05\n",
      "6.727272727272727e-05\n",
      "6.545454545454546e-05\n",
      "6.363636363636363e-05\n",
      "6.181818181818182e-05\n",
      "6e-05\n",
      "5.8181818181818185e-05\n",
      "5.636363636363637e-05\n",
      "5.4545454545454546e-05\n",
      "5.272727272727273e-05\n",
      "5.0909090909090914e-05\n",
      "4.909090909090909e-05\n",
      "4.7272727272727275e-05\n",
      "4.545454545454546e-05\n",
      "4.363636363636364e-05\n",
      "4.181818181818182e-05\n",
      "4e-05\n",
      "3.818181818181819e-05\n",
      "3.6363636363636364e-05\n",
      "3.454545454545455e-05\n",
      "3.272727272727273e-05\n",
      "3.090909090909091e-05\n",
      "2.9090909090909093e-05\n",
      "2.7272727272727273e-05\n",
      "2.5454545454545457e-05\n",
      "2.3636363636363637e-05\n",
      "2.181818181818182e-05\n",
      "2e-05\n",
      "1.8181818181818182e-05\n",
      "1.6363636363636366e-05\n",
      "1.4545454545454546e-05\n",
      "1.2727272727272728e-05\n",
      "1.090909090909091e-05\n",
      "9.090909090909091e-06\n",
      "7.272727272727273e-06\n",
      "5.454545454545455e-06\n",
      "3.6363636363636366e-06\n",
      "1.8181818181818183e-06\n",
      "0.0\n",
      "Model accuracy: 91.51%\n"
     ]
    }
   ],
   "source": [
    "### training\n",
    "model.train()\n",
    "for epoch in range(n_epochs):\n",
    "    for start in batch_start:\n",
    "        X_batch = X_train[start:start+batch_size]\n",
    "        y_batch = y_train[start:start+batch_size]\n",
    "        y_pred = model(X_batch)\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "        print(lr)\n",
    " \n",
    "# evaluate accuracy after training\n",
    "model.eval()\n",
    "y_pred = model(X_test)\n",
    "acc = (y_pred.round() == y_test).float().mean()\n",
    "acc = float(acc)\n",
    "print(\"Model accuracy: %.2f%%\" % (acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
