{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lunli/anaconda3/envs/ML Algo/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/lunli/anaconda3/envs/ML Algo/lib/python3.10/site-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "# torch\n",
    "from torch import Generator\n",
    "from peft import LoraConfig, TaskType\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "# transformer\n",
    "from transformers.optimization import SchedulerType\n",
    "# native\n",
    "from NlpAnalytics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### global var\n",
    "USE_LORA = False\n",
    "GENERATOR = Generator().manual_seed(42)\n",
    "PATH = 'NlpAnalytics/data/dummy_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lunli/anaconda3/envs/ML Algo/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "###  Data Loader\n",
    "# get tokenizer\n",
    "tokenizer = BertLoader(load_tokenizer=True).tokenizer\n",
    "# create DatasetNLP\n",
    "train_sup_ds = DatasetNLP(input_df=pd.read_csv(os.path.join(PATH, \"sup_train.csv\")), tokenizer=tokenizer, cols_label=['label'])\n",
    "train_unsup_ds = DatasetNLP(input_df=pd.read_csv(os.path.join(PATH, \"unsup_train.csv\"))[:16], tokenizer=tokenizer, cols_to_tokenize=['orig_text', 'aug_text'])\n",
    "test_ds = DatasetNLP(input_df=pd.read_csv(os.path.join(PATH, \"sup_test.csv\"))[:16], tokenizer=tokenizer, cols_to_tokenize=['text'], cols_label=['label'])\n",
    "# assemble data loader\n",
    "datamodeler = {\n",
    "    DataLoaderType.TRAINING: DataLoader(train_sup_ds, sampler=RandomSampler(train_sup_ds, generator=GENERATOR), batch_size=8),\n",
    "    DataLoaderType.TRAINING_UNLABELED: DataLoader(train_unsup_ds, sampler=RandomSampler(train_unsup_ds, generator=GENERATOR), batch_size=8),\n",
    "    DataLoaderType.VALIDATION: DataLoader(test_ds, sampler=RandomSampler(test_ds, generator=GENERATOR), batch_size=8)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "### model loader\n",
    "loader = BertClassifierLoader(ClassifierType.BERT_CLASSIFIER_HF, \"bert-base-uncased\", 2, 0.1, load_tokenizer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### loss functions\n",
    "loss_dict = {\n",
    "    'sup': get_loss_functions(LossFuncType.CROSS_ENTROPY, reduce='none'), \n",
    "    'unsup': get_loss_functions(LossFuncType.KL_DIV, reduce='none')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lunli/anaconda3/envs/ML Algo/lib/python3.10/site-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "### set up optimizer\n",
    "if not USE_LORA:\n",
    "    optimizer = AdamNLP.newNLPAdam(loader.model, {'embeddings':True, 'encoder': 9}, lr=2e-4)\n",
    "    model = optimizer.get_model_transformed()\n",
    "else:\n",
    "    lora_config = LoraConfig(task_type=TaskType.SEQ_CLS, target_modules=[\"query\", \"key\", \"value\"], r=1, lora_alpha=1, lora_dropout=0.1)\n",
    "    optimizer = AdamNLP.newNLPAdam_LORA(loader.model, lora_config)\n",
    "    model = optimizer.get_model_transformed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 1, the mean sup loss is: 0.7799562811851501, and accuracy is: 0.625.\n",
      "Validation accuracy is: 0.0.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lunli/anaconda3/envs/ML Algo/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Epoch:  50%|█████     | 1/2 [00:01<00:01,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 2, the mean sup loss is: 0.8996076583862305, and accuracy is: 0.5.\n",
      "Validation accuracy is: 0.0.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 2/2 [00:02<00:00,  1.32s/it]\n"
     ]
    }
   ],
   "source": [
    "### Training\n",
    "trainer = TrainerUDA(model, datamodeler, loss_dict, optimizer)\n",
    "trainer.train(2, schedule_type=SchedulerType.CONSTANT, save_model_freq=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML Algo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
